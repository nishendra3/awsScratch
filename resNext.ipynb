{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_file(source_directory, destination_directory, filename):\n",
    "    \"\"\"\n",
    "    Utility function used to copy a file from a source_directory to a destination_directory\n",
    "    \"\"\"\n",
    "    destination_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(source_directory/filename, destination_directory/filename)\n",
    "    \n",
    "def organize_train_valid_dataset(root, dest, labels, valid_probability=0.1):\n",
    "    \"\"\"\n",
    "    Creates the train, train_valid and valid folders respecting PyTorch's ImageDataset structure, performing\n",
    "    train/validation split based on the given percentage\n",
    "    \"\"\"\n",
    "    source_directory = root/'images'\n",
    "    \n",
    "    for index, row in labels.iterrows():\n",
    "        img_index = row['filename'].split('.')[0]  # The filename is the name of the image except the extension\n",
    "        img_class = row['quantity']\n",
    "\n",
    "        # Randomly assign the image to the valid dataset with probability 'valid_probability'\n",
    "        channel = Path('train') if random()>valid_probability else Path('valid')\n",
    "        destination_directory = dest/channel/str(img_class)\n",
    "\n",
    "        # Copy the image to either the train or valid folder, and also to the train_valid folder\n",
    "        copy_file(source_directory, destination_directory, row['filename'])\n",
    "        copy_file(source_directory, dest/'train_valid'/str(img_class), row['filename'])\n",
    "\n",
    "def organize_test_dataset(root, dest, labels):\n",
    "    \"\"\"\n",
    "    Creates the test folder respecting PyTorch's ImageDataset structure, using a dummy 'undefined' label\n",
    "    \"\"\"\n",
    "    source_directory = root/'images'\n",
    "        \n",
    "    for index, row in labels.iterrows():\n",
    "        img_index = row['filename'].split('.')[0]  # The index is the name of the image except the extension\n",
    "\n",
    "        channel = Path('test')\n",
    "        destination_directory = dest/channel/'undefined'\n",
    "        \n",
    "        try:\n",
    "            copy_file(source_directory, destination_directory, row['filename'])\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "root = Path('.')\n",
    "dest = Path('.')\n",
    "dest.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Read in the labels DataFrame with a label for each image\n",
    "train = pd.read_csv(f'{root}/train.csv')\n",
    "test = pd.read_csv(f'{root}/test.csv')\n",
    "\n",
    "# Create the train/train_valid/valid folder structure\n",
    "valid_probability = 0.1\n",
    "organize_train_valid_dataset(root, dest, train, valid_probability)\n",
    "\n",
    "# Create the test folder structure\n",
    "organize_test_dataset(root, dest, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76fde39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fada16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "train_dataset, train_valid_dataset = [torchvision.datasets.ImageFolder(folder, transform=train_transforms) for folder in [root/'train', root/'train_valid']]\n",
    "\n",
    "\n",
    "valid_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "valid_dataset, test_dataset = [torchvision.datasets.ImageFolder(folder, transform=valid_transforms) for folder in [root/'valid', root/'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying to balance the data -- in progress\n",
    "\n",
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]                                  \n",
    "    return weight                                                                         \n",
    "                                                                                \n",
    "# For unbalanced dataset we create a weighted sampler                       \n",
    "#weights = make_weights_for_balanced_classes(train_dataset.imgs, 6)                                                                \n",
    "#weights = torch.DoubleTensor(weights)                                       \n",
    "#sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))                     \n",
    "                                                                                \n",
    "#train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, sampler = sampler, num_workers=2*num_gpus, pin_memory=True) \n",
    "\n",
    "#train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n",
    "#train_valid_dataloader = torch.utils.data.DataLoader(train_valid_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n",
    "\n",
    "#valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=256, shuffle=False, num_workers=2*num_gpus, pin_memory=True)\n",
    "#test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2*num_gpus, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938853fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76462cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n",
    "train_valid_dataloader = torch.utils.data.DataLoader(train_valid_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=256, shuffle=False, num_workers=2*num_gpus, pin_memory=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2*num_gpus, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    resnext = torchvision.models.resnext50_32x4d(pretrained=True)\n",
    "    num_ftrs = resnext.fc.in_features\n",
    "    #resnext.fc = torch.nn.Linear(num_ftrs, 6)\n",
    "    #resnext.classifier[6] = torch.nn.Linear(resnext.classifier[6].in_features, 6)\n",
    "    resnext.fc = nn.Sequential(\n",
    "        nn.BatchNorm1d(num_ftrs),\n",
    "        nn.Linear(in_features=num_ftrs, out_features=512, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(in_features=512, out_features=6, bias=False)\n",
    "    )\n",
    "    #torch.nn.init.xavier_uniform_(resnext.fc.weight) # initialize the weights of the new layer\n",
    "    return resnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbecfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying some other model -- not working\n",
    "\n",
    "#import timm\n",
    "#def get_net_exp():\n",
    "#    convnext_tiny = timm.create_model('convnext_small_in22ft1k', pretrained=True)\n",
    "#    num_ftrs = convnext_tiny.head.fc.in_features\n",
    "#    convnext_tiny.head.fc = torch.nn.Linear(in_features=num_ftrs, out_features=6, bias=True)\n",
    "    \n",
    "    #resnext = torchvision.models.vit_b_16(pretrained=True)\n",
    "    \n",
    "    #resnext.fc = torch.nn.Linear(num_ftrs, 6)\n",
    "    #resnext.classifier[6] = torch.nn.Linear(resnext.classifier[6].in_features, 6)\n",
    "#    torch.nn.init.xavier_uniform_(convnext_tiny.head.fc.weight) # initialize the weights of the new layer\n",
    "#    return convnext_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d56f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, child in resnext.named_children():\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convnext_base = timm.create_model('convnext_base', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f81597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convnext_base = timm.create_model('convnext_base', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5311a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#timm.list_models('*convnext*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler=None, epochs=10, device='cpu', checkpoint_epochs=10):\n",
    "    start = time.time()\n",
    "    print(f'Training for {epochs} epochs on {device}')\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        \n",
    "        net.train()  # put network in train mode for Dropout and Batch Normalization\n",
    "        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n",
    "        train_accuracy = torch.tensor(0., device=device)\n",
    "        for X, y in train_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = net(X)\n",
    "            loss = criterion(preds, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_loss += loss * train_dataloader.batch_size\n",
    "                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n",
    "        \n",
    "        if valid_dataloader is not None:\n",
    "            net.eval()  # put network in train mode for Dropout and Batch Normalization\n",
    "            valid_loss = torch.tensor(0., device=device)\n",
    "            valid_accuracy = torch.tensor(0., device=device)\n",
    "            with torch.no_grad():\n",
    "                for X, y in valid_dataloader:\n",
    "                    X = X.to(device)\n",
    "                    y = y.to(device)\n",
    "                    preds = net(X)\n",
    "                    loss = criterion(preds, y)\n",
    "\n",
    "                    valid_loss += loss * valid_dataloader.batch_size\n",
    "                    valid_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n",
    "        \n",
    "        if scheduler is not None: \n",
    "            scheduler.step()\n",
    "            \n",
    "        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n",
    "        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n",
    "        \n",
    "        if valid_dataloader is not None:\n",
    "            print(f'Valid loss: {valid_loss/len(valid_dataloader.dataset):.2f}')\n",
    "            print(f'Valid accuracy: {100*valid_accuracy/len(valid_dataloader.dataset):.2f}')\n",
    "        \n",
    "        if epoch%checkpoint_epochs==0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': net.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, './checkpoint.pth.tar')\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'Total training time: {end-start:.1f} seconds')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096791d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr, epochs = 1e-3, 10\n",
    "\n",
    "# get network and move it to GPU\n",
    "net = get_net().to(device)\n",
    "\n",
    "# standard CrossEntropy Loss for multi-class classification problems\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizer for the network parameters\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# start training process\n",
    "net = train(net, train_dataloader, valid_dataloader, criterion, optimizer, None, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d97d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
